{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CD\n",
    "### 1. Write a program to search for a given pattern in a set of files. It should support regular expressions. It should work similar to grep and fgrep of Linux environment. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main.c\n",
    "```\n",
    "#include <stdio.h>\n",
    "int main(){\n",
    "    int x = 0;\n",
    "    if(x)\n",
    "    x--;\n",
    "    else\n",
    "    ++x;\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of tokens =  34\n",
      "\n",
      "No. of keywords =  5\n",
      "['int', 'int', 'if', 'else', 'return']\n",
      "\n",
      "No. of special symbols =  1\n",
      "['#']\n",
      "\n",
      "No. of oparators =  7\n",
      "['<', '>', '=', '-', '-', '+', '+']\n",
      "\n",
      "No. of identifiers =  8\n",
      "['include', 'stdio', 'h', 'main', 'x', 'x', 'x', 'x']\n",
      "\n",
      "No. of constants =  2\n",
      "['0', '0']\n",
      "\n",
      "No. of delimiters =  11\n",
      "['.', '(', ')', '{', ';', '(', ')', ';', ';', ';', '}']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# s = input(\"Enter filename : \")\n",
    "s = 'main.c'\n",
    "f = open(s, 'r')\n",
    "text = f.read()\n",
    "\n",
    "symbols = ['!', '@', '#', '$', '%', '&', '^', '*']\n",
    "oparators = ['+', '-', '*', '/', '=', '+=', '-=', '==', '<', '>', '<=', '>=']\n",
    "keywords = ['auto','break', 'case', 'char', 'const', 'continue', 'default', 'do', \n",
    "\t\t\t'double', 'else', 'enum', 'extern', 'float', 'for', 'goto', 'if', \n",
    "\t\t\t'int', 'long', 'register', 'return', 'short', 'signed', 'sizeof', 'static', \n",
    "\t\t\t'struct', 'switch', 'typedef', 'union', 'unsigned', 'void', 'volatile', 'while']\n",
    "delimiters = [' ', '\t', '.', ',', '\\n', ';', '(', ')', '<', '>', '{', '}', '[', ']']\n",
    "\n",
    "\n",
    "in_keywords = []\n",
    "in_spl_symbols = []\n",
    "in_oparators = []\n",
    "in_delimiters = []\n",
    "in_identifiers = []\n",
    "in_constants = []\n",
    "\n",
    "tokens = []\n",
    "isStr = False\n",
    "isWord = False\n",
    "isCmt = 0\n",
    "token = ''\n",
    "\n",
    "for i in text:\n",
    "\tif i == '/':\n",
    "\t\tisCmt = isCmt+1\n",
    "\n",
    "\telif isCmt == 2:\n",
    "\t\tif i == '\\n':\n",
    "\t\t\ttoken = ''\n",
    "\t\t\tisCmt = 0\n",
    "\t\n",
    "\telif i == '\"' or i == \"'\":\n",
    "\t\tif isStr:\n",
    "\t\t\ttokens.append(token)\n",
    "\t\t\ttoken = ''\n",
    "\t\tisStr = not isStr \n",
    "\n",
    "\telif isStr:\n",
    "\t\ttoken = token+i\n",
    "    \n",
    "\telif i in symbols:\n",
    "\t\ttokens.append(i)\n",
    "           \n",
    "\telif i.isalnum() and not isWord:\n",
    "\t\tisWord = True\n",
    "\t\ttoken = i\n",
    "    \n",
    "\telif (i in delimiters) or (i in oparators):\n",
    "\t\tif token:\n",
    "\t\t\ttokens.append(token)\n",
    "\t\t\ttoken = ''\n",
    "        \n",
    "\t\tif not (i==' ' or i=='\\n' or i=='\t'):\n",
    "\t\t\ttokens.append(i)\n",
    "\n",
    "\telif isWord:\n",
    "\t\ttoken = token+i\n",
    "\n",
    "\n",
    "for token in tokens:\n",
    "\tif token in symbols:\n",
    "\t\tin_spl_symbols.append(token)\n",
    "\n",
    "\telif token in oparators:\n",
    "\t\tin_oparators.append(token)\n",
    "\n",
    "\telif token in keywords:\n",
    "\t\tin_keywords.append(token)\n",
    "\t\t\t\t\n",
    "\telif re.search(\"^[_a-zA-Z][_a-zA-Z0-9]*$\",token):\n",
    "\t\tin_identifiers.append(token)\n",
    "\t\t\n",
    "\telif token in delimiters:\n",
    "\t\tin_delimiters.append(token)\n",
    "\t\t\n",
    "\telse:\n",
    "\t\tin_constants.append(token)\n",
    "\t\n",
    "\t\t\t\t\t\t\n",
    "print(\"No of tokens = \", len(tokens))   \n",
    "print(\"\\n\\nNo. of keywords = \",len(in_keywords))\n",
    "print(\"\\nNo. of special symbols = \",len(in_spl_symbols))\n",
    "print(\"\\nNo. of oparators = \",len(in_oparators))\n",
    "print(\"\\nNo. of identifiers = \",len(in_identifiers))\n",
    "print(\"\\nNo. of constants = \",len(in_constants))\n",
    "print(\"\\nNo. of delimiters = \",len(in_delimiters))\n",
    "f.close()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write programs to implement DFA and NFA.(Input : DFA or NFAand a string and Output : Verification of any given string for acceptance.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ACCEPTED'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class DFA:\n",
    "    def __init__(self,Q,S,D,q0,F) -> None:\n",
    "        self.Q = Q\n",
    "        self.S = S # Sigma - Alphabets\n",
    "        self.D = D # Delta \n",
    "        self.s = q0\n",
    "        self.F = F\n",
    "    \n",
    "    def check(self,inp):\n",
    "        if inp == '' and self.s == 0 :\n",
    "            return 'ACCEPTED'\n",
    "        state = self.s\n",
    "        for i in inp:\n",
    "            if i not in self.S:\n",
    "                return 'Rejected - Not an Alphabet'\n",
    "            state = self.D[(state,i)]\n",
    "        if state in self.F:\n",
    "            return 'ACCEPTED'\n",
    "        return 'Rejected - Not in Language'\n",
    "\n",
    "class NFA(DFA):\n",
    "\n",
    "    def check(self,inp):\n",
    "        if inp == '' and self.s == 0 :\n",
    "            return 'ACCEPTED'\n",
    "        state = [self.s]\n",
    "        for i in inp:\n",
    "            if i not in self.S:\n",
    "                return 'Rejected - Not an Alphabet'\n",
    "            newstate = []\n",
    "            for j in state:\n",
    "                if (j,i) in self.D:\n",
    "                    tempstate = self.D[(j,i)]\n",
    "                    for k in tempstate:\n",
    "                        newstate.append(k)\n",
    "            state = list(set(newstate))\n",
    "        for s in state:\n",
    "            if s in self.F:\n",
    "                return 'ACCEPTED'\n",
    "        return 'Rejected - Not in Language'\n",
    "\n",
    "\n",
    "dfa = DFA(3,('a','b'),{(0,'a'):1,(0,'b'):0,(1,'a'):2,(1,'b'):1,(2,'a'):0,(2,'b'):2},0,{0})\n",
    "dfa.check('aababaaab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rejected - Not in Language'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfa.check('aabbaa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ACCEPTED'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nfa = NFA(2,('a','b'),{(0,'a'):[1],(1,'b'):[0]},0,{1})\n",
    "nfa.check('abababa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rejected - Not in Language'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nfa.check('abab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Design a PDA for any given CNF. Simulate the processing of a string using the PDA and show the parse tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaaabbbbb           [Z         ] q    \n",
      "aaaaabbbbb           [ZX        ] q    \n",
      "aaaabbbbb            [ZXX       ] q    \n",
      "aaabbbbb             [ZXXX      ] q    \n",
      "aabbbbb              [ZXXXX     ] q    \n",
      "abbbbb               [ZXXXXX    ] q    \n",
      "bbbbb                [ZXXXX     ] p    \n",
      "bbbb                 [ZXXX      ] p    \n",
      "bbb                  [ZXX       ] p    \n",
      "bb                   [ZX        ] p    \n",
      "b                    [Z         ] p    \n",
      "ε                    [          ] acc  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Accepted'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class DPDA:\n",
    "    \n",
    "    def __init__(self, trf, input, state):\n",
    "        \n",
    "        self.head = 0\n",
    "        self.trf = {}\n",
    "        self.state = str(state)\n",
    "        self.input = input\n",
    "        self.trf = trf\n",
    "        self.stack = ['Z']\n",
    "        \n",
    "    def step(self):\n",
    "        \n",
    "        a = self.input[self.head]\n",
    "        s = self.stack.pop()\n",
    "        state, ss = self.trf.get((self.state, a, s))\n",
    "        if ss != 'ε':\n",
    "            for s in ss[::-1]:\n",
    "                self.stack.append(s)\n",
    "        self.state = state\n",
    "        print('{:20s} [{:10s}] {:5s}'.format(self.input[self.head:], \n",
    "                       ''.join(self.stack), self.state))        \n",
    "        self.head += 1\n",
    "    \n",
    "    def run(self):\n",
    "        \n",
    "        print('{:20s} [{:10s}] {:5s}'.format(self.input[self.head:], \n",
    "                              ''.join(self.stack), self.state))\n",
    "        \n",
    "        while self.head  < len(self.input):\n",
    "            self.step()\n",
    "\n",
    "        s = self.stack.pop()        \n",
    "        if self.trf.get((self.state, 'ε', s)):\n",
    "            state, ss = self.trf.get((self.state, 'ε', s))\n",
    "            self.state = state        \n",
    "            print('{:20s} [{:10s}] {:5s}'.format('ε', \n",
    "                 ''.join(self.stack), self.state))\n",
    "        if self.state == 'acc':\n",
    "            return \"Accepted\"\n",
    "        return \"Rejected\"\n",
    "        \n",
    "# run DPDA to accept the input string a^9b^9\n",
    "DPDA({('q', 'a', 'Z'): ('q', 'XZ'),\n",
    "     ('q', 'a', 'X'): ('q', 'XX'),\n",
    "     ('q', 'b', 'X'): ('p', 'ε'),\n",
    "     ('p', 'b', 'X'): ('p', 'ε'),\n",
    "     ('p', 'ε', 'Z'): ('acc', 'Z'),\n",
    "    }, \n",
    "    'aaaaabbbbb', 'q').run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Grammar = (('S','A','B'),('a','b'),{'S':['AB','BC'],'A':['BA','a'],'B':['CC','b'],'C':['AB','a']},'S') #VTPS\n",
    "\n",
    "def CYK(Grammar,inp):\n",
    "    n = len(inp)\n",
    "    DP = [[[] for j in range(n)] for i in range(n)]\n",
    "    for i in range(n):\n",
    "        for k,v in Grammar[2].items():\n",
    "            for r in v:\n",
    "                if r == inp[i] :\n",
    "                    DP[i][i].append(k)\n",
    "    for i in range(2,n+1):\n",
    "        for j in range(n-i+1):\n",
    "            k = j+i-1\n",
    "            for l in range(j,k-1):\n",
    "                for prod,rules in Grammar[2].items():\n",
    "                    for rule in rules:\n",
    "                        if len(rule) > 1 and rule[0] == DP[j][l] and rule[1] == DP[l+1][k] :\n",
    "                            DP[j][k].append(prod)\n",
    "                            dis(DP,n)\n",
    "def dis(DP,n):\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            print(DP[i][j],end='\\t\\t')\n",
    "        print()\n",
    "\n",
    "    \n",
    "CYK(Grammar , 'baaba')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "non_terminals = [\"S\", \"N\", \"D\", \"P\",\n",
    "\t\t\t\t\"V\", \"A\"]\n",
    "terminals = [\"a\",\"b\", \"c\", \"d\",\n",
    "\t\t\t\"e\", \"f\",\n",
    "\t\t\t\"g\", \"h\",\"i\"]\n",
    "\n",
    "# Rules of the grammar\n",
    "R = {\n",
    "\t\"S\": [[\"D\", \"N\"]],\n",
    "\t\"N\": [[\"P\", \"N\"], [\"b\"],\n",
    "\t\t\t[\"c\"], [\"d\"]],\n",
    "\t\"P\": [[\"V\", \"A\"], [\"f\"],\n",
    "\t\t\t[\"c\"], [\"e\"]],\n",
    "\t\"D\": [[\"a\"]],\n",
    "\t\"V\": [[\"g\"], [\"i\"]],\n",
    "\t\"A\": [[\"f\"], [\"c\"], [\"e\"],\n",
    "\t\t[\"h\"]]\n",
    "\t}\n",
    "\n",
    "def cykParse(inp):\n",
    "\tn = len(inp)\n",
    "\tT = [[set([]) for j in range(n)] for i in range(n)]\n",
    "\n",
    "\tfor j in range(0, n):\n",
    "\t\tfor lhs, rule in R.items():\n",
    "\t\t\tfor rhs in rule:\n",
    "\t\t\t\tif len(rhs) == 1 and rhs[0] == inp[j]:\n",
    "\t\t\t\t\tT[j][j].add(lhs)\n",
    "\n",
    "\t\tfor i in range(j, -1, -1):\n",
    "\t\t\tfor k in range(i, j + 1):\t\n",
    "\t\t\t\tfor lhs, rule in R.items():\n",
    "\t\t\t\t\tfor rhs in rule:\n",
    "\t\t\t\t\t\tif len(rhs) == 2 and rhs[0] in T[i][k] and rhs[1] in T[k + 1][j]:\n",
    "\t\t\t\t\t\t\tT[i][j].add(lhs)\n",
    "\n",
    "\tif len(T[0][n-1]) != 0:\n",
    "\t\tprint(\"True\")\n",
    "\telse:\n",
    "\t\tprint(\"False\")\n",
    "\n",
    "inp = \"a g f c b\".split()\n",
    "cykParse(inp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Design a Lexical analyzer for identifying different types of tokens used in C language. Note: The reserved keywords such as if, else, class, structetc must be reported as invalid identifiers. C allows identifier names to begin with underscore character too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# s = input(\"Enter filename : \")\n",
    "s = 'main.c'\n",
    "f = open(s, 'r')\n",
    "text = f.read()\n",
    "\n",
    "symbols = ['!', '@', '#', '$', '%', '&', '^', '*']\n",
    "oparators = ['+', '-', '*', '/', '=', '+=', '-=', '==', '<', '>', '<=', '>=']\n",
    "keywords = ['auto','break', 'case', 'char', 'const', 'continue', 'default', 'do', \n",
    "\t\t\t'double', 'else', 'enum', 'extern', 'float', 'for', 'goto', 'if', \n",
    "\t\t\t'int', 'long', 'register', 'return', 'short', 'signed', 'sizeof', 'static', \n",
    "\t\t\t'struct', 'switch', 'typedef', 'union', 'unsigned', 'void', 'volatile', 'while']\n",
    "delimiters = [' ', '\t', '.', ',', '\\n', ';', '(', ')', '<', '>', '{', '}', '[', ']']\n",
    "\n",
    "\n",
    "in_keywords = []\n",
    "in_spl_symbols = []\n",
    "in_oparators = []\n",
    "in_delimiters = []\n",
    "in_identifiers = []\n",
    "in_constants = []\n",
    "\n",
    "tokens = []\n",
    "isStr = False\n",
    "isWord = False\n",
    "isCmt = 0\n",
    "token = ''\n",
    "\n",
    "for i in text:\n",
    "\tif i == '/':\n",
    "\t\tisCmt = isCmt+1\n",
    "\n",
    "\telif isCmt == 2:\n",
    "\t\tif i == '\\n':\n",
    "\t\t\ttoken = ''\n",
    "\t\t\tisCmt = 0\n",
    "\t\n",
    "\telif i == '\"' or i == \"'\":\n",
    "\t\tif isStr:\n",
    "\t\t\ttokens.append(token)\n",
    "\t\t\ttoken = ''\n",
    "\t\tisStr = not isStr \n",
    "\n",
    "\telif isStr:\n",
    "\t\ttoken = token+i\n",
    "    \n",
    "\telif i in symbols:\n",
    "\t\ttokens.append(i)\n",
    "           \n",
    "\telif i.isalnum() and not isWord:\n",
    "\t\tisWord = True\n",
    "\t\ttoken = i\n",
    "    \n",
    "\telif (i in delimiters) or (i in oparators):\n",
    "\t\tif token:\n",
    "\t\t\ttokens.append(token)\n",
    "\t\t\ttoken = ''\n",
    "        \n",
    "\t\tif not (i==' ' or i=='\\n' or i=='\t'):\n",
    "\t\t\ttokens.append(i)\n",
    "\n",
    "\telif isWord:\n",
    "\t\ttoken = token+i\n",
    "\n",
    "\n",
    "for token in tokens:\n",
    "\tif token in symbols:\n",
    "\t\tin_spl_symbols.append(token)\n",
    "\n",
    "\telif token in oparators:\n",
    "\t\tin_oparators.append(token)\n",
    "\n",
    "\telif token in keywords:\n",
    "\t\tin_keywords.append(token)\n",
    "\t\t\t\t\n",
    "\telif re.search(\"^[_a-zA-Z][_a-zA-Z0-9]*$\",token):\n",
    "\t\tin_identifiers.append(token)\n",
    "\t\t\n",
    "\telif token in delimiters:\n",
    "\t\tin_delimiters.append(token)\n",
    "\t\t\n",
    "\telse:\n",
    "\t\tin_constants.append(token)\n",
    "\t\n",
    "\t\t\t\t\t\t\n",
    "print(\"No of tokens = \", len(tokens))   \n",
    "print(\"\\nNo. of keywords = \",len(in_keywords))\n",
    "print(in_keywords);\n",
    "print(\"\\nNo. of special symbols = \",len(in_spl_symbols))\n",
    "print(in_spl_symbols);\n",
    "print(\"\\nNo. of oparators = \",len(in_oparators))\n",
    "print(in_oparators);\n",
    "print(\"\\nNo. of identifiers = \",len(in_identifiers))\n",
    "print(in_identifiers);\n",
    "print(\"\\nNo. of constants = \",len(in_constants))\n",
    "print(in_constants);\n",
    "print(\"\\nNo. of delimiters = \",len(in_delimiters))\n",
    "print(in_delimiters);\n",
    "f.close()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Program to recognize the identifiers, if and switch statements of C using a lexical analyzer generator tool. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Consider the following grammar: \n",
    "#### S --> ABC \n",
    "#### A-->abA | ab \n",
    "#### B--> b | BC \n",
    "#### C--> c | cC \n",
    "### Design any shift reduced parser which accepts a string and tells whether the string is accepted by above grammar or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STACK\t\t\tISUT\t\t\tACTION\n",
      "['$', 0, 'a', 3]    \t\tbbc$    \t\tSHIFT S3\n",
      "['$', 0, 'a', 3, 'b', 6]    \t\tbc$    \t\tSHIFT S6\n",
      "['$', 0, 'A']    \t\tbc$    \t\tREDUCE R3\n",
      "['$', 0, 'A', 2]    \t\tbc$    \t\tGOTO 2\n",
      "['$', 0, 'A', 2, 'b', 4]    \t\tc$    \t\tSHIFT S4\n",
      "['$', 0, 'A', 2, 'B']    \t\tc$    \t\tREDUCE R4\n",
      "['$', 0, 'A', 2, 'B', 5]    \t\tc$    \t\tGOTO 5\n",
      "['$', 0, 'A', 2, 'B', 5, 'c', 8]    \t\t$    \t\tSHIFT S8\n",
      "['$', 0, 'A', 2, 'B', 5, 'C']    \t\t$    \t\tREDUCE R6\n",
      "['$', 0, 'A', 2, 'B', 5, 'C', 7]    \t\t$    \t\tGOTO 7\n",
      "['$', 0, 'S']    \t\t$    \t\tREDUCE R1\n",
      "['$', 0, 'S', 1]    \t\t$    \t\tGOTO 1\n",
      "['ACC']    \t\t$    \t\tACCEPT ACC\n",
      "STACK\t\t\tISUT\t\t\tACTION\n",
      "['$', 0, 'a', 3]    \t\tbbbcc$    \t\tSHIFT S3\n",
      "['$', 0, 'a', 3, 'b', 6]    \t\tbbcc$    \t\tSHIFT S6\n",
      "['$', 0, 'A']    \t\tbbcc$    \t\tREDUCE R3\n",
      "['$', 0, 'A', 2]    \t\tbbcc$    \t\tGOTO 2\n",
      "['$', 0, 'A', 2, 'b', 4]    \t\tbcc$    \t\tSHIFT S4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Accepted', 'Rejected')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = {'S': 'ABC', 'A': ['abA', 'ab'], 'B': ['b', 'BC'], 'C': ['c', 'cC']}\n",
    "# G = (V,T,P,S)\n",
    "G = (('S', 'A', 'B', 'C'), ('a', 'b', 'c', '$'), g, 'S')\n",
    "\n",
    "Items = 11\n",
    "\n",
    "pt_action = {\n",
    "    (0, 'a'): 'S3',\n",
    "    (1, '$'): 'ACC',\n",
    "    (2, 'b'): 'S4',\n",
    "    (3, 'b'): 'S6',\n",
    "    (4, 'c'): 'R4',\n",
    "    (5, 'c'): 'S8',\n",
    "    (6, 'a'): 'S3',\n",
    "    (6, 'b'): 'R3',\n",
    "    (7, 'c'): 'R5',\n",
    "    (7, '$'): 'R1',\n",
    "    (8, 'c'): 'S8',\n",
    "    (8, '$'): 'R6',\n",
    "    (9, 'c'): 'R7',\n",
    "    (9, '$'): 'R7',\n",
    "    (10, 'b'): 'R2'\n",
    "}\n",
    "pt_goto = {\n",
    "    (0, 'S'): 1,\n",
    "    (0, 'A'): 2,\n",
    "    (2, 'B'): 5,\n",
    "    (5, 'C'): 7,\n",
    "    (6, 'A'): 10,\n",
    "    (8, 'C'): 9\n",
    "}\n",
    "\n",
    "R = {\n",
    "    'R1': ['S', 'ABC'],\n",
    "    'R2': ['A', 'abA'],\n",
    "    'R3': ['A', 'ab'],\n",
    "    'R4': ['B', 'b'],\n",
    "    'R5': ['B', 'BC'],\n",
    "    'R6': ['C', 'c'],\n",
    "    'R7': ['C', 'cC']\n",
    "}\n",
    "\n",
    "\n",
    "def SRParser(s: str):\n",
    "    s = s + '$'\n",
    "    stack = ['$', 0]\n",
    "    sptr = 0\n",
    "    print('STACK\\t\\t\\tISUT\\t\\t\\tACTION')\n",
    "    while(stack[-1] != 'ACC' or sptr < len(s)):\n",
    "        if stack[-1] in range(Items):\n",
    "            if s[sptr] in G[1]:\n",
    "                if (stack[-1], s[sptr]) not in pt_action:\n",
    "                    break\n",
    "                act = pt_action[(stack[-1], s[sptr])]\n",
    "                if 'S' in act:\n",
    "                    stack.append(s[sptr])\n",
    "                    stack.append(int(act[1]))\n",
    "                    sptr += 1\n",
    "                    print(f'{stack}    \\t\\t{s[sptr:]}    \\t\\tSHIFT {act}')\n",
    "                elif 'R' in act:\n",
    "                    red_move = R[act]\n",
    "                    popnum = len(red_move[1]) * 2\n",
    "                    for i in range(popnum):\n",
    "                        stack.pop()\n",
    "                    stack.append(red_move[0])\n",
    "                    print(f'{stack}    \\t\\t{s[sptr:]}    \\t\\tREDUCE {act}')\n",
    "                elif 'ACC' in act:\n",
    "                    popnum = 2 * 2\n",
    "                    for i in range(popnum):\n",
    "                        stack.pop()\n",
    "                    stack.append('ACC')\n",
    "                    print(f'{stack}    \\t\\t{s[sptr:]}    \\t\\tACCEPT {act}')\n",
    "                else:\n",
    "                    break\n",
    "        elif stack[-1] in G[0]:\n",
    "            stack.append(pt_goto[(stack[-2], stack[-1])])\n",
    "            print(f'{stack}    \\t\\t{s[sptr:]}    \\t\\tGOTO {stack[-1]}')\n",
    "        else:\n",
    "            break\n",
    "    if stack[0] == 'ACC':\n",
    "        return \"Accepted\"\n",
    "    return \"Rejected\"\n",
    "\n",
    "\n",
    "SRParser('abbc'),SRParser('abbbcc')\n",
    "#SRParser('abbcc'),SRParser('ababbcc')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. YACC program that reads the input expression and convert it to post fix expression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a075be670f002415fc65291a584e903cef0587159d6bdf77e827b87cdcbb0bd0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
